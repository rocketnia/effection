## TODO: Remove hypersnippet-shaped effects from Effection

We should move them to Punctaffy.

They didn't pan out the way they were originally designed, much less develop into something that intermingled with Effection's deterministic concurrency system. Once we figure out a better design for them, they'll probably go in Punctaffy anyway. After all, they're likely to depend on hypersnippet-shaped syntax, some hypersnippet-shaped syntax operations may benefit from hypersnippet-shaped effects, and although the original design didn't pan out, it was helpful to think back on when designing Punctaffy's hypernests since the binding scopes correspond with hypernest bumps.



## TODO: Rename Effection

I think I'm not confident enough that this library deserves the name. One possible alternative is "Lathe Extensibility."



## TODO: Add a process calculus to Effection

It'll need a few particular features:

- No-op and fused processes.
- Splitting authorized names and getting unauthorized names from them.
- Writing and reading definitions keyed by a writer-authorized name.
- Writing and reading private definitions keyed by a writer-authorized name and a reader-authorized name.
- OWA extensibility: Pubbing and subbing, where the pubbing is keyed by a pubber-authorized name and the subbing is keyed by a subber-authorized name. Pubbing supplies a function argument, and subbing supplies a process-returning function. The processes obtained by calling each function on each argument are performed concurrently.
- CWA extensibility: Writing contributions and reading contribution sets. This one is complicated. Writing supplies a writer-authorized name and a reader-authorized name and... something else (TODO: What exactly?) to ensure the writer "knows about" this CWA hub. (That way we can process the reads only after every process which knows about the hub is complete.) Reading supplies the reader-authorized name and a function that takes the set of contributions (as a table keyed by the names obtained from the writer-authorized names) and returns a process.

Hmm, how about this for CWA extensibility:

Splitting contribution tickets, writing contributions, and reading contribution sets. Writing supplies an unspent contribution ticket and a value. Reading supplies an unspent authorized name, a process-returning function that takes an unspent contribution ticket, and a process-returning function that takes the set of contributions (as a table keyed by the names obtained from the writer-authorized names).

If all the processes complete and a contribution ticket remains unspent, that's an error. In particular, this is true for the typical Cene use case of running the Cene macroexpander on a bunch of Cene code to generate a compiled module. This means modules typically can't have closed-world extensibility, which is good, because the Era notion of "module" is an open-world concept by design.

However, when Cene code is combined in the form of a set of "services" -- a set of "main" functions to call concurrently, potentially each coming from a different module -- the program can potentially pass contribution tickets between services to perform closed-world extensibility. To support this use case, it will probably be helpful to have another state resource:

- Distributing and claiming contribution tickets keyed by a distibutor-authorized name. Distributing supplies an unspent contribution ticket. Claiming supplies a process-returning function that takes an unspent contribution ticket.

This way, a service could split a ticket exactly the number of times it needs to be split to pass it to all the other services that care about it. It seems like the only other way to do this would be to treat the number of times to split the ticket as a configuration setting and inject it from some service that stands apart from the distributor and all (or all but one of) the claimants. The same place this number is specified would also have to specify where each of the tickets should be written to for its claimant to see it.

This boilerplate configuration would be a symptom of a failure in our CWA extensibility system. "Write boilerplate configuration that lists all the files in the program" is an extensibility technique available to just about any programming language, and we want to do better than that. So we'll definitely want distribute-claim hubs.

Hmm. Distribute-claim hubs might challenge the open-world nature of modules, since a module build can perhaps distribute to a hub in such a way that the quined module defines things differently than the original does. Is this actually possible? If it is, then are there some restrictions we can place on the distribute and claim effects (and the module system) to ensure it isn't?

---

Before this process calculus is useful, it'll also need Effection-unsafe, but Racket-safe, ways to create definition spaces out of thin air and to run and to extract result values from these effects.

The most Effection-safe we can make this is to have a single global definition space, a Racket thread that constantly cranks through its reads and writes, and a Racket-effectful procedure for running a process. The procedure's effects make it Effection-unsafe, but it's still Effection-safe to run it at the top level of a Racket module.

---

Hmm, when we're using the CWA extensibility hubs, what happens if we don't know all the services that a service is aware of until we've run its computation a little? Then it won't be possible to say for sure that it *won't* claim tickets from ticket distribution hubs that in fact it was written with no knowledge of. How do we fix this?

Perhaps a service isn't just a process-returning `main` function that takes a unique name and a qualify function. Perhaps it also needs to come with a set of names of ticket distribution hubs it will claim from.

Ooh, how about this: To claim from a ticket distribution hub, it's necessary to provide an unspent "claim ticket." A service is a process-returning `main` function that receives a unique name, a qualify function, and an unspent claim ticket. The service can split its claim ticket any number of times (even using distribution hubs to split it), but once a service's last claim ticket is spent, its process can no longer claim any tickets. Perhaps a claim ticket can only be spent by the one process that's associated with it, so that it's more understandable why spending them all would prohibit that process from making further claims.

Hmm... but is that any different than the `promise-not-to-contribute` style? Perhaps all we need is `promise-not-to-claim-any-more-tickets`.

Hmm, usually all a service needs to be able to do is claim a ticket from each ticket hub it knows about, promise not to claim any more tickets, and then split those tickets however many times it needs. But sometimes a service may define things which act as metaprogramming utilities for another service, which might help the other service claim other tickets.

Ooh, what if we had "familiarity tickets"? A service starts its life with familiarity of some particular CWA extension hubs of other services, and each of those relationships gives it a familiarity ticket. It can use familiarity tickets to make contributions to those hubs. We can think of this more generally as a ticket that represents familiarity with a whole module, package, or service, which can be used to perform various imports... but right now, there seems to be only one thing we need this ticket for, which is to contribute to a CWA extension hub.

With that in mind, the operations of a CWA extension hub are a little different.

- Contributing to the hub requires a familiarity ticket, a contributor-authorized name, and a value.

- Reading from the hub requires a reader-authorized name, a process-returning function that takes a familiarity ticket, and a process-returning function that takes a table mapping contributor-authorized names to values. (TODO: Do we really need the reader-authorized name?)



## TODO: Add Effection utilities for side-effectful programming

Make all the usual read and write effects take another parameter that acts as the definition space to perform the lookup in. In an effectful program, this parameter will tend to be passed in automatically in a dynamically scoped style; where Racket has `current-parameterization`, effect systems based on Effection's monotonic state will tend to have `current-definition-space`.

Add a way to create a fresh definition space that views and extends another one, i.e. so that writes to it don't pass through to the original, but reads do. This will be good for creating local dynamic scopes to hold dynamically scoped bindings.

To support creating dynamically scoped regions that enforce purity during their extent, add a way to create a fresh empty definition space -- or rather, not quite empty, since it would be odd not to have access to function implementations in Cene. Never mind, then; Cene can use the above operation to create a fresh definition space that views and extends whatever definition space the interpreter uses to look up struct tags' function implementations. Or Cene can read and write function implementations on a different definition space than it usually uses for other definitions.
